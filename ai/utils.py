# ai/utils.py
# intakes/data/mfds_foods.csvì—ì„œ í‰ê· ê°’ì„ ì§‘ê³„í•´ ê°€ëŠ  ì˜ì–‘ì†Œ(macros)ë¥¼ ì¶”ì •.
# MFDS í•œê¸€ í—¤ë” ìë™ ì¸ì‹ + ì •ê·œí™” + ì˜â†’í•œ ë™ì˜ì–´ + í¼ì§€ ë§¤ì¹­(rapidfuzz) ì§€ì›

from __future__ import annotations

import csv
import re
import math
from collections import defaultdict
from functools import lru_cache
from pathlib import Path
from typing import Dict, Iterable, Optional, List, Tuple

from django.conf import settings

try:
    # í¼ì§€ ë§¤ì¹­ (ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ None ì²˜ë¦¬)
    from rapidfuzz import fuzz, process
except Exception:  # pragma: no cover
    fuzz = None
    process = None

__all__ = [
    "estimate_macros_from_csv",
    "load_mfds_rows",
    "_match_csv_by_label",
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½/ì˜µì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FUZZY_SCORE_THRESHOLD = float(getattr(settings, "FUZZY_SCORE_THRESHOLD", 88.0))  # 0~100 ì¶”ì²œ 82~90
FUZZY_CANDIDATES_LIMIT = int(getattr(settings, "FUZZY_CANDIDATES_LIMIT", 5))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë™ì˜ì–´(ì˜â†’í•œ) ë§¤í•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EN_KO_SYNONYMS = {
    "hamburger": "í–„ë²„ê±°",
    "cheeseburger": "ì¹˜ì¦ˆë²„ê±°",
    "spaghetti bolognese": "ë³¼ë¡œë„¤ì œ ìŠ¤íŒŒê²Œí‹°",
    "bolognese": "ë³¼ë¡œë„¤ì œ",
    "spaghetti": "ìŠ¤íŒŒê²Œí‹°",
    "pasta": "íŒŒìŠ¤íƒ€",
    "carbonara": "ê¹Œë¥´ë³´ë‚˜ë¼",
    "ramen": "ë¼ë©´",
    "udon": "ìš°ë™",
    "soba": "ì†Œë°”",
    "sushi": "ìŠ¤ì‹œ",
    "kimbap": "ê¹€ë°¥",
    "gimbap": "ê¹€ë°¥",
    "fried chicken": "ì¹˜í‚¨",
    "pork cutlet": "ëˆê¹ŒìŠ¤",
    "tonkatsu": "ëˆê¹ŒìŠ¤",
    "donkatsu": "ëˆê¹ŒìŠ¤",
    "tteokbokki": "ë–¡ë³¶ì´",
    "rice cake": "ë–¡",
}

# ---------- ë‚´ë¶€ ìœ í‹¸ ----------

def _safe_float(v, default: float = 0.0) -> float:
    try:
        if v is None or v == "":
            return default
        return float(v)
    except Exception:
        return default

def _to_float_any(v) -> Optional[float]:
    if v is None:
        return None
    if isinstance(v, (int, float)):
        x = float(v)
        return None if (math.isnan(x) or math.isinf(x)) else x
    s = str(v).strip()
    if not s:
        return None
    s = s.replace(",", "")  # 1,234.5 â†’ 1234.5
    try:
        x = float(s)
        return None if (math.isnan(x) or math.isinf(x)) else x
    except Exception:
        return None

# í•œê¸€/ì˜ë¬¸/ìˆ«ìë§Œ ë‚¨ê¸°ê³ , í•˜ì´í”ˆ/ì–¸ë”ìŠ¤ì½”ì–´ëŠ” ê³µë°±ìœ¼ë¡œ ì¹˜í™˜
_norm_pat = re.compile(r"[^\wê°€-í£]+")

def _normalize_label(s: str) -> str:
    """
    ê°„ë‹¨ ë¼ë²¨ ì •ê·œí™”:
      - ì†Œë¬¸ìí™”
      - _, - ë¥¼ ê³µë°±ìœ¼ë¡œ
      - í•œê¸€/ì˜ë¬¸/ìˆ«ì ì™¸ ê¸°í˜¸ ì œê±°
      - ì—°ì† ê³µë°± ì¶•ì†Œ
    """
    if not s:
        return ""
    s = s.strip().lower().replace("_", " ").replace("-", " ")
    s = _norm_pat.sub(" ", s)
    s = re.sub(r"\s+", " ", s)
    return s

def _pick_key(row: Dict[str, str], patterns: List[re.Pattern]) -> Optional[str]:
    """
    rowì˜ ì»¬ëŸ¼í‚¤ë“¤ ì¤‘ ì •ê·œì‹ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤ì¹­ë˜ëŠ” ì²« í‚¤ ë°˜í™˜ (ìš°ì„ ìˆœìœ„: ì•ì—ì„œ ë’¤ë¡œ)
    """
    keys = list(row.keys())
    for p in patterns:
        for k in keys:  # ì›ë¬¸ í‚¤
            if k and p.search(str(k)):
                return k
        for k in keys:  # ì •ê·œí™” í‚¤(ì†Œë¬¸ì/ê³µë°±ì œê±°)
            kk = re.sub(r"\s+", "", str(k).lower())
            if kk and p.search(kk):
                return k
    return None

@lru_cache(maxsize=1)
def load_mfds_rows() -> Iterable[Dict[str, str]]:
    """
    MFDS CSVë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œ. (ê°„ë‹¨ ìºì‹œ)
    ê¶Œì¥ ì»¬ëŸ¼(ìˆìœ¼ë©´ ìë™ ì¶”ì¶œ):
      - ì‹í’ˆëª…, ëŒ€í‘œì‹í’ˆëª…
      - ì—ë„ˆì§€(kcal), ë‹¨ë°±ì§ˆ(g), íƒ„ìˆ˜í™”ë¬¼(g), ì§€ë°©(g)
    """
    p = getattr(settings, "MFDS_FOOD_CSV", None)
    path: Optional[Path] = None
    if p:
        try:
            path = Path(p)
        except Exception:
            path = None
    if not path:
        # ë°±ì—… ê²½ë¡œ
        try:
            path = Path(settings.BASE_DIR) / "intakes" / "data" / "mfds_foods.csv"
        except Exception:
            path = None
    if not path or not path.exists():
        return []

    rows = []
    try:
        with open(path, newline="", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                rows.append(row)
    except FileNotFoundError:
        return []
    return rows

# ---------- í¼ë¸”ë¦­ API ----------

def estimate_macros_from_csv(label_ko: str) -> Optional[Dict[str, float]]:
    """
    ì£¼ì–´ì§„ í•œê¸€ ë¼ë²¨(ì˜ˆ: 'ê¹€ë°¥', 'ìƒëŸ¬ë“œ')ì„ CSVì—ì„œ ì°¾ì•„
    í‰ê·  ì¹¼ë¡œë¦¬/ë‹¨ë°±ì§ˆ/íƒ„ìˆ˜í™”ë¬¼/ì§€ë°©ì„ ì¶”ì •í•´ ë°˜í™˜.
    ë§¤ì¹­ ê·œì¹™(ìˆœì„œëŒ€ë¡œ ì‹œë„):
      1) ì •ê·œí™”ëœ ì™„ì „ì¼ì¹˜
      2) ë¶€ë¶„ì¼ì¹˜(í¬í•¨ ê´€ê³„)
    ì¼ì¹˜ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ None.
    """
    if not label_ko:
        return None

    target_norm = _normalize_label(label_ko)
    if not target_norm:
        return None

    rows = load_mfds_rows()
    if not rows:
        return None

    exact_hits = []
    partial_hits = []

    for row in rows:
        # MFDS í•œê¸€ ìš°ì„ 
        name = (row.get("ì‹í’ˆëª…") or row.get("ëŒ€í‘œì‹í’ˆëª…") or row.get("name_ko") or row.get("label_ko") or "").strip()
        if not name:
            continue

        name_norm = _normalize_label(name)
        if not name_norm:
            continue

        if name_norm == target_norm:
            exact_hits.append(row)
        elif (target_norm in name_norm) or (name_norm in target_norm):
            partial_hits.append(row)

    def _aggregate(hit_rows: Iterable[Dict[str, str]]) -> Optional[Dict[str, float]]:
        totals = defaultdict(float)
        count = 0
        for r in hit_rows:
            # _row_to_macrosë¥¼ í†µì¼ ì‚¬ìš© (í—¤ë” í¸ì°¨ ëŒ€ì‘)
            m = _row_to_macros(r)
            totals["calories"] += m["calories"]
            totals["protein"]  += m["protein"]
            totals["carb"]     += m["carb"]
            totals["fat"]      += m["fat"]
            count += 1
        if count == 0:
            return None
        return {
            "calories": round(totals["calories"] / count, 2),
            "protein":  round(totals["protein"]  / count, 2),
            "carb":     round(totals["carb"]     / count, 2),
            "fat":      round(totals["fat"]      / count, 2),
        }

    # 1) ì™„ì „ì¼ì¹˜ ìš°ì„ 
    agg = _aggregate(exact_hits)
    if agg:
        return agg

    # 2) ë¶€ë¶„ì¼ì¹˜ ë°±ì—…
    agg = _aggregate(partial_hits)
    if agg:
        return agg

    return None

# ---------- MFDS í•œê¸€ í—¤ë” ìµœì í™”: í–‰ â†’ í‘œì¤€ macros ----------

def _row_to_macros(row: Dict[str, str]) -> Dict[str, float]:
    """
    MFDS í•œê¸€ í—¤ë” ìµœì í™”:
    1ìˆœìœ„: ì •í™• í‚¤ë¡œ ì¶”ì¶œ
      - ì´ë¦„: ì‹í’ˆëª… (ì—†ìœ¼ë©´ ëŒ€í‘œì‹í’ˆëª…)
      - kcal: ì—ë„ˆì§€(kcal)
      - ë‹¨ë°±ì§ˆ: ë‹¨ë°±ì§ˆ(g)
      - íƒ„ìˆ˜í™”ë¬¼: íƒ„ìˆ˜í™”ë¬¼(g)
      - ì§€ë°©: ì§€ë°©(g)
    2ìˆœìœ„: ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ í´ë°± (100g ë³€í˜• ì—´ í¬í•¨)
    """
    # â”€â”€ ì´ë¦„ â”€â”€
    name_ko = (row.get("ì‹í’ˆëª…") or row.get("ëŒ€í‘œì‹í’ˆëª…") or row.get("name_ko") or row.get("label_ko") or "").strip()
    if not name_ko:
        name_key = _pick_key(row, [
            re.compile(r"(ì‹í’ˆëª…|ëŒ€í‘œì‹í’ˆëª…|name_?ko|label_?ko|í’ˆëª©ëª…|í•œê¸€ëª…|ì œí’ˆëª…)", re.I),
        ])
        name_ko = (row.get(name_key) or "").strip() if name_key else ""

    # â”€â”€ ì •í™• í‚¤ ìš°ì„  â”€â”€
    def _get_num(*keys) -> Optional[float]:
        for k in keys:
            if k in row:
                v = _to_float_any(row.get(k))
                if v is not None:
                    return v
        return None

    kcal    = _get_num("ì—ë„ˆì§€(kcal)", "kcal", "calories", "energy_kcal")
    protein = _get_num("ë‹¨ë°±ì§ˆ(g)", "protein", "protein_g")
    carb    = _get_num("íƒ„ìˆ˜í™”ë¬¼(g)", "carb", "carbs", "carbohydrate", "carbohydrate_g")
    fat     = _get_num("ì§€ë°©(g)", "fat", "fat_g")

    # â”€â”€ íŒ¨í„´ í´ë°± â”€â”€
    if kcal is None:
        kcal_key = _pick_key(row, [
            re.compile(r"(ì—ë„ˆì§€|ì—´ëŸ‰|kcal)", re.I),
            re.compile(r"(energy.*kcal|calories?)", re.I),
        ])
        if kcal_key: kcal = _to_float_any(row.get(kcal_key))

    if protein is None:
        protein_key = _pick_key(row, [re.compile(r"(ë‹¨ë°±ì§ˆ|protein(_g)?)", re.I)])
        if protein_key: protein = _to_float_any(row.get(protein_key))

    if carb is None:
        carb_key = _pick_key(row, [re.compile(r"(íƒ„ìˆ˜í™”ë¬¼|carbo(hydrate)?s?)", re.I)])
        if carb_key: carb = _to_float_any(row.get(carb_key))

    if fat is None:
        fat_key = _pick_key(row, [re.compile(r"(ì§€ë°©|fat(_g)?)", re.I)])
        if fat_key: fat = _to_float_any(row.get(fat_key))

    # â”€â”€ 100g ë³€í˜• ì—´ í´ë°± â”€â”€
    if kcal is None:
        kcal100_key = _pick_key(row, [re.compile(r"(100g.*ì—ë„ˆì§€|ì—ë„ˆì§€.*100g|kcal.*100g|100g.*kcal)", re.I)])
        if kcal100_key: kcal = _to_float_any(row.get(kcal100_key))
    if protein is None:
        pro100_key = _pick_key(row, [re.compile(r"(100g.*ë‹¨ë°±ì§ˆ|ë‹¨ë°±ì§ˆ.*100g|protein.*100g)", re.I)])
        if pro100_key: protein = _to_float_any(row.get(pro100_key))
    if carb is None:
        carb100_key = _pick_key(row, [re.compile(r"(100g.*íƒ„ìˆ˜í™”ë¬¼|íƒ„ìˆ˜í™”ë¬¼.*100g|carb.*100g)", re.I)])
        if carb100_key: carb = _to_float_any(row.get(carb100_key))
    if fat is None:
        fat100_key = _pick_key(row, [re.compile(r"(100g.*ì§€ë°©|ì§€ë°©.*100g|fat.*100g)", re.I)])
        if fat100_key: fat = _to_float_any(row.get(fat100_key))

    # í´ë°±: ì—†ìœ¼ë©´ 0
    kcal    = round(kcal or 0.0, 1)
    protein = round(protein or 0.0, 1)
    carb    = round(carb or 0.0, 1)
    fat     = round(fat or 0.0, 1)

    return {
        "label_ko": name_ko,
        "calories": kcal,
        "protein":  protein,
        "carb":     carb,
        "fat":      fat,
    }

# ---------- CSV ë§¤ì¹­(ì˜/í•œ/ë™ì˜ì–´ + í¼ì§€) ----------

def _match_csv_by_label(pred_label: str) -> Optional[Dict[str, float]]:
    """
    AI ë¼ë²¨ê³¼ CSVì˜ ì´ë¦„(ko/en/synonyms)ì„ ìµœëŒ€í•œ ë§¤ì¹­
    - ìš°ì„ ìˆœìœ„: exact en â†’ exact ko â†’ synonyms â†’ ë¶€ë¶„ í¬í•¨(en/ko) â†’ ğŸ”¥ í¼ì§€ ë§¤ì¹­(ko ëª©ë¡)
    - ì˜ë¼ë²¨ì€ EN_KO_SYNONYMSë¥¼ í†µí•´ í•œê¸€ë¡œ ì¹˜í™˜ í›„ ì‹œë„
    """
    rows = load_mfds_rows()
    if not rows:
        return None

    # 0) ì…ë ¥ ì •ê·œí™”
    label_raw = (pred_label or "").strip()
    label = _normalize_label(label_raw)
    if not label:
        return None

    # 0-1) ì˜â†’í•œ ë™ì˜ì–´ ì¹˜í™˜
    for en, ko in EN_KO_SYNONYMS.items():
        if _normalize_label(en) == label:
            label_raw = ko
            label = _normalize_label(label_raw)
            break

    # 1) exact en
    for r in rows:
        if _normalize_label(r.get("name_en") or "") == label:
            return _row_to_macros(r)

    # 2) exact ko (MFDS í•œê¸€ í‚¤ í¬í•¨)
    for r in rows:
        if _normalize_label(r.get("ì‹í’ˆëª…") or "") == label:
            return _row_to_macros(r)
        if _normalize_label(r.get("ëŒ€í‘œì‹í’ˆëª…") or "") == label:
            return _row_to_macros(r)
        if _normalize_label(r.get("name_ko") or "") == label:
            return _row_to_macros(r)
        if _normalize_label(r.get("label_ko") or "") == label:
            return _row_to_macros(r)

    # 3) synonyms (ì‰¼í‘œ/ì„¸ë¯¸ì½œë¡  êµ¬ë¶„)
    for r in rows:
        syn = r.get("synonyms") or r.get("alias") or ""
        if syn:
            cand = [_normalize_label(x) for x in str(syn).replace(";", ",").split(",") if x.strip()]
            if label in cand:
                return _row_to_macros(r)

    # 4) ë¶€ë¶„ í¬í•¨ (en/ko)
    for r in rows:
        if label and (
            label in _normalize_label(r.get("name_en") or "") or
            label in _normalize_label(r.get("ì‹í’ˆëª…") or "") or
            label in _normalize_label(r.get("ëŒ€í‘œì‹í’ˆëª…") or "") or
            label in _normalize_label(r.get("name_ko") or "") or
            label in _normalize_label(r.get("label_ko") or "")
        ):
            return _row_to_macros(r)

    # 5) ğŸ”¥ í¼ì§€ ë§¤ì¹­ (ì‹¤ì œ í•­ëª©ëª…ë§Œ í›„ë³´ë¡œ â†’ ì˜¤íƒ ê°ì†Œ)
    if process and fuzz:
        ko_names: List[str] = []
        idx_map: Dict[str, List[int]] = {}
        for i, r in enumerate(rows):
            for key in ("ì‹í’ˆëª…", "ëŒ€í‘œì‹í’ˆëª…", "name_ko", "label_ko"):
                nm = (r.get(key) or "").strip()
                if not nm:
                    continue
                if nm not in idx_map:
                    idx_map[nm] = []
                    ko_names.append(nm)
                idx_map[nm].append(i)

        def _score(a: str, b: str) -> float:
            # ì •ê·œí™”ëœ ì§ˆì˜ vs ì›ë¬¸ í›„ë³´
            return max(
                fuzz.token_set_ratio(a, _normalize_label(b)),
                fuzz.partial_ratio(a, _normalize_label(b)),
            )

        matches: List[Tuple[str, float, int]] = process.extract(
            query=_normalize_label(label_raw),   # ì •ê·œí™”ëœ ì§ˆì˜
            choices=ko_names,                   # ì›ë¬¸ í›„ë³´(ì •ê·œí™”ëŠ” scorerì—ì„œ ìˆ˜í–‰)
            scorer=_score,
            limit=FUZZY_CANDIDATES_LIMIT,
        )

        for name, score, _ in matches:
            if score >= FUZZY_SCORE_THRESHOLD:
                for row_idx in idx_map.get(name, []):
                    return _row_to_macros(rows[row_idx])

    # í¼ì§€ ë§¤ì¹­ ë¶ˆê°€ or ì„ê³„ ë¯¸ë‹¬ â†’ ì‹¤íŒ¨
    return None
