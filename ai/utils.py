# ai/utils.py
# intakes/data/mfds_foods.csvì—ì„œ í‰ê· ê°’ì„ ì§‘ê³„í•´ ê°€ëŠ  ì˜ì–‘ì†Œ(macros)ë¥¼ ì¶”ì •.
# MFDS í•œê¸€ í—¤ë” ìžë™ ì¸ì‹ + ì •ê·œí™” + ì˜â†’í•œ ë™ì˜ì–´ + í¼ì§€ ë§¤ì¹­(rapidfuzz) ì§€ì›
# âœ… per100g(ë³´ì¡°) + weight_g(1íšŒì œê³µëŸ‰ g) + total(=per100g*weight/100) êµ¬ì¡°ì²´ê¹Œì§€ ì œê³µ

from __future__ import annotations

import csv
import re
import math
from collections import defaultdict
from functools import lru_cache
from pathlib import Path
from typing import Dict, Iterable, Optional, List, Tuple

from django.conf import settings

try:
    # í¼ì§€ ë§¤ì¹­ (ì„¤ì¹˜ë˜ì–´ ìžˆì§€ ì•Šìœ¼ë©´ None ì²˜ë¦¬)
    from rapidfuzz import fuzz, process
except Exception:  # pragma: no cover
    fuzz = None
    process = None

__all__ = [
    # ê¸°ì¡´ ê³µê°œ API
    "estimate_macros_from_csv",
    "load_mfds_rows",
    "_match_csv_by_label",
    # ì‹ ê·œ ê³µê°œ API (ê¶Œìž¥)
    "match_csv_entry",          # â† ë¼ë²¨ â†’ {label_ko, weight_g, per100g, total}
    "parse_weight_g",
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í™˜ê²½/ì˜µì…˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FUZZY_SCORE_THRESHOLD = float(getattr(settings, "FUZZY_SCORE_THRESHOLD", 88.0))  # 0~100 ì¶”ì²œ 82~90
FUZZY_CANDIDATES_LIMIT = int(getattr(settings, "FUZZY_CANDIDATES_LIMIT", 5))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë™ì˜ì–´(ì˜â†’í•œ) ë§¤í•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EN_KO_SYNONYMS = {
    "hamburger": "í–„ë²„ê±°",
    "cheeseburger": "ì¹˜ì¦ˆë²„ê±°",
    "burger": "í–„ë²„ê±°",
    "spaghetti bolognese": "ë³¼ë¡œë„¤ì œ ìŠ¤íŒŒê²Œí‹°",
    "bolognese": "ë³¼ë¡œë„¤ì œ",
    "spaghetti": "ìŠ¤íŒŒê²Œí‹°",
    "pasta": "íŒŒìŠ¤íƒ€",
    "carbonara": "ê¹Œë¥´ë³´ë‚˜ë¼",
    "ramen": "ë¼ë©´",
    "udon": "ìš°ë™",
    "soba": "ì†Œë°”",
    "sushi": "ìŠ¤ì‹œ",
    "kimbap": "ê¹€ë°¥",
    "gimbap": "ê¹€ë°¥",
    "fried chicken": "ì¹˜í‚¨",
    "chicken": "ì¹˜í‚¨",
    "pork cutlet": "ëˆê¹ŒìŠ¤",
    "tonkatsu": "ëˆê¹ŒìŠ¤",
    "donkatsu": "ëˆê¹ŒìŠ¤",
    "tteokbokki": "ë–¡ë³¶ì´",
    "rice cake": "ë–¡",
    "bibimbap": "ë¹„ë¹”ë°¥",
    "bulgogi": "ë¶ˆê³ ê¸°",
    "yogurt": "ìš”ê±°íŠ¸",
    "sandwich": "ìƒŒë“œìœ„ì¹˜",
    "steak": "ìŠ¤í…Œì´í¬",
    "pizza": "í”¼ìž",
    "curry": "ì¹´ë ˆ",
    "apple": "ì‚¬ê³¼",
    "banana": "ë°”ë‚˜ë‚˜",
    "coffee": "ì»¤í”¼",
}

# ---------- ë‚´ë¶€ ìœ í‹¸ ----------

def _safe_float(v, default: float = 0.0) -> float:
    try:
        if v is None or v == "":
            return default
        return float(v)
    except Exception:
        return default

def _to_float_any(v) -> Optional[float]:
    if v is None:
        return None
    if isinstance(v, (int, float)):
        x = float(v)
        return None if (math.isnan(x) or math.isinf(x)) else x
    s = str(v).strip()
    if not s:
        return None
    s = s.replace(",", "")  # 1,234.5 â†’ 1234.5
    try:
        x = float(s)
        return None if (math.isnan(x) or math.isinf(x)) else x
    except Exception:
        return None

# í•œê¸€/ì˜ë¬¸/ìˆ«ìžë§Œ ë‚¨ê¸°ê³ , í•˜ì´í”ˆ/ì–¸ë”ìŠ¤ì½”ì–´ëŠ” ê³µë°±ìœ¼ë¡œ ì¹˜í™˜
_norm_pat = re.compile(r"[^\wê°€-íž£]+")

def _normalize_label(s: str) -> str:
    """
    ê°„ë‹¨ ë¼ë²¨ ì •ê·œí™”:
      - ì†Œë¬¸ìží™”
      - _, - ë¥¼ ê³µë°±ìœ¼ë¡œ
      - í•œê¸€/ì˜ë¬¸/ìˆ«ìž ì™¸ ê¸°í˜¸ ì œê±°
      - ì—°ì† ê³µë°± ì¶•ì†Œ
    """
    if not s:
        return ""
    s = s.strip().lower().replace("_", " ").replace("-", " ")
    s = _norm_pat.sub(" ", s)
    s = re.sub(r"\s+", " ", s)
    return s

def _pick_key(row: Dict[str, str], patterns: List[re.Pattern]) -> Optional[str]:
    """
    rowì˜ ì»¬ëŸ¼í‚¤ë“¤ ì¤‘ ì •ê·œì‹ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤ì¹­ë˜ëŠ” ì²« í‚¤ ë°˜í™˜ (ìš°ì„ ìˆœìœ„: ì•žì—ì„œ ë’¤ë¡œ)
    """
    keys = list(row.keys())
    for p in patterns:
        for k in keys:  # ì›ë¬¸ í‚¤
            if k and p.search(str(k)):
                return k
        for k in keys:  # ì •ê·œí™” í‚¤(ì†Œë¬¸ìž/ê³µë°±ì œê±°)
            kk = re.sub(r"\s+", "", str(k).lower())
            if kk and p.search(kk):
                return k
    return None

@lru_cache(maxsize=1)
def load_mfds_rows() -> Iterable[Dict[str, str]]:
    """
    MFDS CSVë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œ. (ê°„ë‹¨ ìºì‹œ)
    ê¶Œìž¥ ì»¬ëŸ¼(ìžˆìœ¼ë©´ ìžë™ ì¶”ì¶œ):
      - ì‹í’ˆëª…, ëŒ€í‘œì‹í’ˆëª…
      - ì—ë„ˆì§€(kcal), ë‹¨ë°±ì§ˆ(g), íƒ„ìˆ˜í™”ë¬¼(g), ì§€ë°©(g)
      - ì‹í’ˆì¤‘ëŸ‰ ë˜ëŠ” 1íšŒì œê³µëŸ‰/serving/weight (g)
    """
    p = getattr(settings, "MFDS_FOOD_CSV", None)
    path: Optional[Path] = None
    if p:
        try:
            path = Path(p)
        except Exception:
            path = None
    if not path:
        # ë°±ì—… ê²½ë¡œ
        try:
            path = Path(settings.BASE_DIR) / "intakes" / "data" / "mfds_foods.csv"
        except Exception:
            path = None
    if not path or not path.exists():
        return []

    rows = []
    try:
        with open(path, newline="", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                rows.append(row)
    except FileNotFoundError:
        return []
    return rows

# ---------- weight íŒŒì‹± ----------

_WEIGHT_NUMBER_RE = re.compile(r"([0-9]+(?:\.[0-9]+)?)\s*g", re.IGNORECASE)

def parse_weight_g(v: Optional[str]) -> float:
    """
    '550g' / 'ì´ì¤‘ëŸ‰ 300 g' / '1ê°œ(180g)' / '180 g/pack' / '300' â†’ 180.0 / 300.0
    ë¹„ì–´ìžˆìœ¼ë©´ 100.0
    """
    if v is None:
        return 100.0
    s = str(v).strip().lower().replace("ê·¸ëž¨", "g")
    m = _WEIGHT_NUMBER_RE.search(s)
    if m:
        try:
            return float(m.group(1))
        except Exception:
            pass
    try:
        return float(s)
    except Exception:
        return 100.0

# ---------- MFDS í•œê¸€ í—¤ë” â†’ í‘œì¤€ macros(per100g) ----------

def _row_to_macros(row: Dict[str, str]) -> Dict[str, float]:
    """
    MFDS í•œê¸€ í—¤ë” ìµœì í™”:
    1ìˆœìœ„: ì •í™• í‚¤ë¡œ ì¶”ì¶œ
      - ì´ë¦„: ì‹í’ˆëª… (ì—†ìœ¼ë©´ ëŒ€í‘œì‹í’ˆëª…)
      - kcal: ì—ë„ˆì§€(kcal)
      - ë‹¨ë°±ì§ˆ: ë‹¨ë°±ì§ˆ(g)
      - íƒ„ìˆ˜í™”ë¬¼: íƒ„ìˆ˜í™”ë¬¼(g)
      - ì§€ë°©: ì§€ë°©(g)
    2ìˆœìœ„: ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ í´ë°± (100g ë³€í˜• ì—´ í¬í•¨)
    â€» ë°˜í™˜: per100g ê¸°ì¤€ ê°’ë“¤ë§Œ (ê¸°ì¡´ í˜¸í™˜)
    """
    # â”€â”€ ì´ë¦„ â”€â”€
    name_ko = (row.get("ì‹í’ˆëª…") or row.get("ëŒ€í‘œì‹í’ˆëª…") or row.get("name_ko") or row.get("label_ko") or "").strip()
    if not name_ko:
        name_key = _pick_key(row, [
            re.compile(r"(ì‹í’ˆëª…|ëŒ€í‘œì‹í’ˆëª…|name_?ko|label_?ko|í’ˆëª©ëª…|í•œê¸€ëª…|ì œí’ˆëª…)", re.I),
        ])
        name_ko = (row.get(name_key) or "").strip() if name_key else ""

    # â”€â”€ ì •í™• í‚¤ ìš°ì„  â”€â”€
    def _get_num(*keys) -> Optional[float]:
        for k in keys:
            if k in row:
                v = _to_float_any(row.get(k))
                if v is not None:
                    return v
        return None

    kcal    = _get_num("ì—ë„ˆì§€(kcal)", "kcal", "calories", "energy_kcal")
    protein = _get_num("ë‹¨ë°±ì§ˆ(g)", "protein", "protein_g")
    carb    = _get_num("íƒ„ìˆ˜í™”ë¬¼(g)", "carb", "carbs", "carbohydrate", "carbohydrate_g")
    fat     = _get_num("ì§€ë°©(g)", "fat", "fat_g")

    # â”€â”€ íŒ¨í„´ í´ë°± â”€â”€
    if kcal is None:
        kcal_key = _pick_key(row, [
            re.compile(r"(ì—ë„ˆì§€|ì—´ëŸ‰|kcal)", re.I),
            re.compile(r"(energy.*kcal|calories?)", re.I),
        ])
        if kcal_key: kcal = _to_float_any(row.get(kcal_key))

    if protein is None:
        protein_key = _pick_key(row, [re.compile(r"(ë‹¨ë°±ì§ˆ|protein(_g)?)", re.I)])
        if protein_key: protein = _to_float_any(row.get(protein_key))

    if carb is None:
        carb_key = _pick_key(row, [re.compile(r"(íƒ„ìˆ˜í™”ë¬¼|carbo(hydrate)?s?)", re.I)])
        if carb_key: carb = _to_float_any(row.get(carb_key))

    if fat is None:
        fat_key = _pick_key(row, [re.compile(r"(ì§€ë°©|fat(_g)?)", re.I)])
        if fat_key: fat = _to_float_any(row.get(fat_key))

    # â”€â”€ 100g ë³€í˜• ì—´ í´ë°± â”€â”€
    if kcal is None:
        kcal100_key = _pick_key(row, [re.compile(r"(100g.*ì—ë„ˆì§€|ì—ë„ˆì§€.*100g|kcal.*100g|100g.*kcal)", re.I)])
        if kcal100_key: kcal = _to_float_any(row.get(kcal100_key))
    if protein is None:
        pro100_key = _pick_key(row, [re.compile(r"(100g.*ë‹¨ë°±ì§ˆ|ë‹¨ë°±ì§ˆ.*100g|protein.*100g)", re.I)])
        if pro100_key: protein = _to_float_any(row.get(pro100_key))
    if carb is None:
        carb100_key = _pick_key(row, [re.compile(r"(100g.*íƒ„ìˆ˜í™”ë¬¼|íƒ„ìˆ˜í™”ë¬¼.*100g|carb.*100g)", re.I)])
        if carb100_key: carb = _to_float_any(row.get(carb100_key))
    if fat is None:
        fat100_key = _pick_key(row, [re.compile(r"(100g.*ì§€ë°©|ì§€ë°©.*100g|fat.*100g)", re.I)])
        if fat100_key: fat = _to_float_any(row.get(fat100_key))

    # í´ë°±: ì—†ìœ¼ë©´ 0
    kcal    = round(kcal or 0.0, 1)
    protein = round(protein or 0.0, 1)
    carb    = round(carb or 0.0, 1)
    fat     = round(fat or 0.0, 1)

    return {
        "label_ko": name_ko,
        "calories": kcal,
        "protein":  protein,
        "carb":     carb,
        "fat":      fat,
    }

# ---------- ì‹ ê·œ: í–‰ â†’ {per100g, total, weight_g} ----------

def _row_to_entry(row: Dict[str, str]) -> Dict[str, object]:
    """í•œ í–‰ì—ì„œ per100g + total + weight_g ë™ì‹œ ì‚°ì¶œ"""
    m = _row_to_macros(row)  # per100g
    # weight
    weight_g = parse_weight_g(
        row.get("ì‹í’ˆì¤‘ëŸ‰") or row.get("1íšŒì œê³µëŸ‰") or row.get("serving") or row.get("weight") or "100"
    )
    scale = (weight_g / 100.0) if weight_g else 1.0
    total = {
        "calories": round(m["calories"] * scale, 1),
        "protein":  round(m["protein"]  * scale, 1),
        "carb":     round(m["carb"]     * scale, 1),
        "fat":      round(m["fat"]      * scale, 1),
    }
    per100g = {
        "calories": m["calories"],
        "protein":  m["protein"],
        "carb":     m["carb"],
        "fat":      m["fat"],
    }
    return {
        "label_ko": m.get("label_ko") or "",
        "weight_g": float(weight_g or 100.0),
        "per100g": per100g,
        "total": total,
    }

# ---------- í¼ë¸”ë¦­ API ----------

def estimate_macros_from_csv(label_ko: str) -> Optional[Dict[str, float]]:
    """
    ì£¼ì–´ì§„ í•œê¸€ ë¼ë²¨(ì˜ˆ: 'ê¹€ë°¥', 'ìƒëŸ¬ë“œ')ì„ CSVì—ì„œ ì°¾ì•„
    í‰ê·  ì¹¼ë¡œë¦¬/ë‹¨ë°±ì§ˆ/íƒ„ìˆ˜í™”ë¬¼/ì§€ë°©ì„ ì¶”ì •í•´ ë°˜í™˜.
    ë§¤ì¹­ ê·œì¹™(ìˆœì„œëŒ€ë¡œ ì‹œë„):
      1) ì •ê·œí™”ëœ ì™„ì „ì¼ì¹˜
      2) ë¶€ë¶„ì¼ì¹˜(í¬í•¨ ê´€ê³„)
    ì¼ì¹˜ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ None.
    â€» per100g í‰ê· ê°’ì„ ë°˜í™˜ (total ê³„ì‚°ì€ í˜¸ì¶œ ì¸¡ì—ì„œ weight_gë¡œ í™˜ì‚°)
    """
    if not label_ko:
        return None

    target_norm = _normalize_label(label_ko)
    if not target_norm:
        return None

    rows = load_mfds_rows()
    if not rows:
        return None

    exact_hits = []
    partial_hits = []

    for row in rows:
        name = (row.get("ì‹í’ˆëª…") or row.get("ëŒ€í‘œì‹í’ˆëª…") or row.get("name_ko") or row.get("label_ko") or "").strip()
        if not name:
            continue

        name_norm = _normalize_label(name)
        if not name_norm:
            continue

        if name_norm == target_norm:
            exact_hits.append(row)
        elif (target_norm in name_norm) or (name_norm in target_norm):
            partial_hits.append(row)

    def _aggregate(hit_rows: Iterable[Dict[str, str]]) -> Optional[Dict[str, float]]:
        totals = defaultdict(float)
        count = 0
        for r in hit_rows:
            m = _row_to_macros(r)
            totals["calories"] += m["calories"]
            totals["protein"]  += m["protein"]
            totals["carb"]     += m["carb"]
            totals["fat"]      += m["fat"]
            count += 1
        if count == 0:
            return None
        return {
            "calories": round(totals["calories"] / count, 2),
            "protein":  round(totals["protein"]  / count, 2),
            "carb":     round(totals["carb"]     / count, 2),
            "fat":      round(totals["fat"]      / count, 2),
        }

    agg = _aggregate(exact_hits) or _aggregate(partial_hits)
    return agg

# ---------- CSV ë§¤ì¹­(ì˜/í•œ/ë™ì˜ì–´ + í¼ì§€) : per100gë§Œ (ê¸°ì¡´ í˜¸í™˜) ----------

def _match_csv_by_label(pred_label: str) -> Optional[Dict[str, float]]:
    """
    AI ë¼ë²¨ê³¼ CSVì˜ ì´ë¦„(ko/en/synonyms)ì„ ìµœëŒ€í•œ ë§¤ì¹­
    - ìš°ì„ ìˆœìœ„: exact en â†’ exact ko â†’ synonyms â†’ ë¶€ë¶„ í¬í•¨(en/ko) â†’ ðŸ”¥ í¼ì§€ ë§¤ì¹­(ko ëª©ë¡)
    - ì˜ë¼ë²¨ì€ EN_KO_SYNONYMSë¥¼ í†µí•´ í•œê¸€ë¡œ ì¹˜í™˜ í›„ ì‹œë„
    â€» ë°˜í™˜: per100g ê¸°ì¤€ ê°’(ê¸°ì¡´ í˜¸ì¶œ í˜¸í™˜)
    """
    rows = load_mfds_rows()
    if not rows:
        return None

    # 0) ìž…ë ¥ ì •ê·œí™”
    label_raw = (pred_label or "").strip()
    label = _normalize_label(label_raw)
    if not label:
        return None

    # 0-1) ì˜â†’í•œ ë™ì˜ì–´ ì¹˜í™˜
    for en, ko in EN_KO_SYNONYMS.items():
        if _normalize_label(en) == label:
            label_raw = ko
            label = _normalize_label(label_raw)
            break

    # 1) exact en
    for r in rows:
        if _normalize_label(r.get("name_en") or "") == label:
            return _row_to_macros(r)

    # 2) exact ko (MFDS í•œê¸€ í‚¤ í¬í•¨)
    for r in rows:
        if _normalize_label(r.get("ì‹í’ˆëª…") or "") == label:
            return _row_to_macros(r)
        if _normalize_label(r.get("ëŒ€í‘œì‹í’ˆëª…") or "") == label:
            return _row_to_macros(r)
        if _normalize_label(r.get("name_ko") or "") == label:
            return _row_to_macros(r)
        if _normalize_label(r.get("label_ko") or "") == label:
            return _row_to_macros(r)

    # 3) synonyms (ì‰¼í‘œ/ì„¸ë¯¸ì½œë¡  êµ¬ë¶„)
    for r in rows:
        syn = r.get("synonyms") or r.get("alias") or ""
        if syn:
            cand = [_normalize_label(x) for x in str(syn).replace(";", ",").split(",") if x.strip()]
            if label in cand:
                return _row_to_macros(r)

    # 4) ë¶€ë¶„ í¬í•¨ (en/ko)
    for r in rows:
        if label and (
            label in _normalize_label(r.get("name_en") or "") or
            label in _normalize_label(r.get("ì‹í’ˆëª…") or "") or
            label in _normalize_label(r.get("ëŒ€í‘œì‹í’ˆëª…") or "") or
            label in _normalize_label(r.get("name_ko") or "") or
            label in _normalize_label(r.get("label_ko") or "")
        ):
            return _row_to_macros(r)

    # 5) ðŸ”¥ í¼ì§€ ë§¤ì¹­
    if process and fuzz:
        ko_names: List[str] = []
        idx_map: Dict[str, List[int]] = {}
        for i, r in enumerate(rows):
            for key in ("ì‹í’ˆëª…", "ëŒ€í‘œì‹í’ˆëª…", "name_ko", "label_ko"):
                nm = (r.get(key) or "").strip()
                if not nm:
                    continue
                if nm not in idx_map:
                    idx_map[nm] = []
                    ko_names.append(nm)
                idx_map[nm].append(i)

        def _score(a: str, b: str) -> float:
            return max(
                fuzz.token_set_ratio(a, _normalize_label(b)),
                fuzz.partial_ratio(a, _normalize_label(b)),
            )

        matches: List[Tuple[str, float, int]] = process.extract(
            query=_normalize_label(label_raw),
            choices=ko_names,
            scorer=_score,
            limit=FUZZY_CANDIDATES_LIMIT,
        )

        for name, score, _ in matches:
            if score >= FUZZY_SCORE_THRESHOLD:
                for row_idx in idx_map.get(name, []):
                    return _row_to_macros(rows[row_idx])

    return None

# ---------- CSV ë§¤ì¹­(ì˜/í•œ/ë™ì˜ì–´ + í¼ì§€) : âœ… êµ¬ì¡°ì²´ ë°˜í™˜(ê¶Œìž¥) ----------

def match_csv_entry(pred_label: str) -> Optional[Dict[str, object]]:
    """
    ë¼ë²¨ â†’ {label_ko, weight_g, per100g, total} êµ¬ì¡°ì²´ ë°˜í™˜ (ì €ìž¥ì€ total ê¸°ì¤€)
    - ì •í™•ì¼ì¹˜(en/ko) â†’ synonyms â†’ ë¶€ë¶„ì¼ì¹˜ â†’ ì˜â†’í•œ ë™ì˜ì–´ ì¹˜í™˜ í›„ ìž¬íƒìƒ‰
    - ë§ˆì§€ë§‰ì— rapidfuzzë¡œ ko í¼ì§€ ë§¤ì¹­
    """
    rows = load_mfds_rows()
    if not rows:
        return None

    label_raw = (pred_label or "").strip()
    label = _normalize_label(label_raw)
    if not label:
        return None

    # english â†’ korean mapping
    mapped = None
    for en, ko in EN_KO_SYNONYMS.items():
        if _normalize_label(en) == label:
            mapped = ko
            break

    def _try_with(query_label: str) -> Optional[Dict[str, object]]:
        qn = _normalize_label(query_label)

        # 1) exact en
        for r in rows:
            if _normalize_label(r.get("name_en") or "") == qn:
                return _row_to_entry(r)
        # 2) exact ko
        for r in rows:
            if _normalize_label(r.get("ì‹í’ˆëª…") or "") == qn:
                return _row_to_entry(r)
            if _normalize_label(r.get("ëŒ€í‘œì‹í’ˆëª…") or "") == qn:
                return _row_to_entry(r)
            if _normalize_label(r.get("name_ko") or "") == qn:
                return _row_to_entry(r)
            if _normalize_label(r.get("label_ko") or "") == qn:
                return _row_to_entry(r)
        # 3) synonyms
        for r in rows:
            syn = r.get("synonyms") or r.get("alias") or ""
            if syn:
                cand = [_normalize_label(x) for x in str(syn).replace(";", ",").split(",") if x.strip()]
                if qn in cand:
                    return _row_to_entry(r)
        # 4) ë¶€ë¶„ í¬í•¨(en/ko)
        for r in rows:
            if qn and (
                qn in _normalize_label(r.get("name_en") or "") or
                qn in _normalize_label(r.get("ì‹í’ˆëª…") or "") or
                qn in _normalize_label(r.get("ëŒ€í‘œì‹í’ˆëª…") or "") or
                qn in _normalize_label(r.get("name_ko") or "") or
                qn in _normalize_label(r.get("label_ko") or "")
            ):
                return _row_to_entry(r)
        return None

    # ìš°ì„ : ì›ë¬¸ìœ¼ë¡œ ì‹œë„
    hit = _try_with(label_raw)
    if hit:
        return hit

    # ì˜ì–´â†’í•œê¸€ ë§¤í•‘ì´ ìžˆìœ¼ë©´ ìž¬ì‹œë„
    if mapped:
        hit = _try_with(mapped)
        if hit:
            return hit

    # í¼ì§€ ë§¤ì¹­
    if process and fuzz:
        ko_names: List[str] = []
        idx_map: Dict[str, List[int]] = {}
        for i, r in enumerate(rows):
            for key in ("ì‹í’ˆëª…", "ëŒ€í‘œì‹í’ˆëª…", "name_ko", "label_ko"):
                nm = (r.get(key) or "").strip()
                if not nm:
                    continue
                if nm not in idx_map:
                    idx_map[nm] = []
                    ko_names.append(nm)
                idx_map[nm].append(i)

        def _score(a: str, b: str) -> float:
            return max(
                fuzz.token_set_ratio(a, _normalize_label(b)),
                fuzz.partial_ratio(a, _normalize_label(b)),
            )

        matches: List[Tuple[str, float, int]] = process.extract(
            query=_normalize_label(mapped or label_raw),
            choices=ko_names,
            scorer=_score,
            limit=FUZZY_CANDIDATES_LIMIT,
        )

        for name, score, _ in matches:
            if score >= FUZZY_SCORE_THRESHOLD:
                for row_idx in idx_map.get(name, []):
                    return _row_to_entry(rows[row_idx])

    return None
